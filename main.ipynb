{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54afdc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from os import walk\n",
    "from os import path\n",
    "import os\n",
    "import matplotlib.pyplot as nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8cb122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "(13132, 3, 75, 75)\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "(13029, 3, 75, 75)\n"
     ]
    }
   ],
   "source": [
    "parasitized = np.empty([13132,3,75,75])\n",
    "count=0\n",
    "for root,dirs,names in walk(r'True_parasitized'):\n",
    "    for name in names:\n",
    "        img_dir = path.join(root, name)\n",
    "        img = Image.open(img_dir).resize((75,75))\n",
    "        parasitized[count]=np.transpose(np.array(img),(2,0,1))/255\n",
    "        count=count+1\n",
    "        if count%1000==0:\n",
    "            print(count)\n",
    "        #np.append(parasitized, [np.array(img)], axis=0)\n",
    "print(parasitized.shape)\n",
    "non_parasitized = np.empty([13029,3,75,75])\n",
    "count=0\n",
    "for root,dirs,names in walk(r'True_uninfected'):\n",
    "    for name in names:\n",
    "        img_dir = path.join(root, name)\n",
    "        img = Image.open(img_dir).resize((75,75))\n",
    "        non_parasitized[count]=np.transpose(np.array(img), (2,0,1))/255\n",
    "        count=count+1\n",
    "        if count%1000==0:\n",
    "            print(count)\n",
    "        #np.append(parasitized, [np.array(img)], axis=0)\n",
    "print(non_parasitized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0f647e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainnData(Dataset):\n",
    "    def __init__(self):\n",
    "        print('Initialized')\n",
    "        #self.parasitized=parasitized\n",
    "        #self.non_parasitized=non_parasitized\n",
    "        self.p_n=len(parasitized)\n",
    "        self.n_n=len(non_parasitized)\n",
    "        print('Done init')\n",
    "    def __len__(self):\n",
    "        return 26161\n",
    "    def __getitem__(self, idx):\n",
    "        images=np.empty([1,3,75,75])\n",
    "        labels=np.zeros([1,2])\n",
    "        \n",
    "        if idx<self.p_n:\n",
    "            images[0]=parasitized[idx]\n",
    "            labels[0][0]=1\n",
    "        else:\n",
    "            images[0]=non_parasitized[idx-self.p_n]\n",
    "            labels[0][1]=1\n",
    "            \n",
    "        return [torch.from_numpy(images).double().to('cuda'), torch.from_numpy(labels).double().to('cuda')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd05308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000/26161]\n",
      "[2000/26161]\n",
      "[3000/26161]\n",
      "[4000/26161]\n",
      "[5000/26161]\n",
      "[6000/26161]\n",
      "[7000/26161]\n",
      "[8000/26161]\n",
      "[9000/26161]\n",
      "[10000/26161]\n",
      "[11000/26161]\n",
      "[12000/26161]\n",
      "[13000/26161]\n",
      "[14000/26161]\n",
      "[15000/26161]\n",
      "[16000/26161]\n",
      "[17000/26161]\n",
      "[18000/26161]\n",
      "[19000/26161]\n",
      "[20000/26161]\n",
      "[21000/26161]\n",
      "[22000/26161]\n",
      "[23000/26161]\n",
      "[24000/26161]\n",
      "[25000/26161]\n",
      "[26000/26161]\n"
     ]
    }
   ],
   "source": [
    "all_dirs = np.empty([len(os.listdir(r'True_uninfected'))+len(os.listdir(r'True_parasitized')),2],dtype=np.chararray)\n",
    "i=0\n",
    "for root,dirs,names in walk(r'True_uninfected'):\n",
    "    for name in names:\n",
    "        img_dir = os.path.join(root,name)\n",
    "        all_dirs[i][0]=img_dir\n",
    "        all_dirs[i][1]=0\n",
    "        i=i+1\n",
    "        if i%1000==0:\n",
    "            print(f\"[{i}/{len(all_dirs)}]\")\n",
    "for root,dirs,names in walk(r'True_parasitized'):\n",
    "    for name in names:\n",
    "        img_dir = os.path.join(root,name)\n",
    "        all_dirs[i][0]=img_dir\n",
    "        all_dirs[i][1]=1\n",
    "        i=i+1\n",
    "        if i%1000==0:\n",
    "            print(f\"[{i}/{len(all_dirs)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75b0d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainingData(Dataset):\n",
    "    def __init__(self, feature_transform=lambda x:x, target_transform=lambda x:x):\n",
    "        self.transform=feature_transform\n",
    "        self.target_transform=target_transform\n",
    "        #gonna try loading everything lazily, so ima skip init\n",
    "        print('')\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(r'True_uninfected'))+len(os.listdir(r'True_parasitized'))\n",
    "    def __getitem__(self, idx):\n",
    "        selected_dirs=[all_dirs[idx][0]]\n",
    "        n=len(selected_dirs)\n",
    "        \n",
    "        images=np.empty([n,3,100,100])\n",
    "        labels=np.zeros([n,2])\n",
    "        for i in range(n):\n",
    "            img=Image.open(r''+str(selected_dirs[i])).resize((100,100))\n",
    "            images[i]=np.transpose(np.array(img),(2,0,1))/255\n",
    "            #labels[i]=all_dirs[idx][1]\n",
    "            if all_dirs[idx][1]==0:\n",
    "                labels[i][0]=1\n",
    "            else:\n",
    "                labels[i][1]=1\n",
    "        return [torch.from_numpy(images).double().to('cuda'), torch.from_numpy(labels).double().to('cuda')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0720b6b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Done init\n"
     ]
    }
   ],
   "source": [
    "dataset = trainnData()\n",
    "dataload = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "vals=(next(iter(dataload)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "97673269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class nett(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(nett, self).__init__()\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Conv2d(3,16,7,stride=1,padding=2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            #nn.Conv2d(32,50,3,stride=1),\n",
    "            #nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(16,10,5,stride=1),\n",
    "            #nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(10,5,3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1280, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000,2)\n",
    "        )\n",
    "        self.conv1=nn.Conv2d(3,16,7,stride=1,padding=2)\n",
    "        self.conv2=nn.Conv2d(16,10,5,stride=1)\n",
    "        self.conv3=nn.Conv2d(10,5,3, stride=1)\n",
    "        self.linear1=nn.Linear(1280, 1000)\n",
    "        self.linear2=nn.Linear(1000,2)\n",
    "        self.maxpool= nn.MaxPool2d(2)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.flat=nn.Flatten()\n",
    "        self.batchnorm1=nn.BatchNorm2d(16)\n",
    "        self.batchnorm2=nn.BatchNorm2d(10)\n",
    "        self.batchnorm3=nn.BatchNorm2d(5)\n",
    "    def forward(self, x):\n",
    "        x=x.double()\n",
    "        x=self.conv1(x)\n",
    "        x=self.batchnorm1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.conv2(x)\n",
    "        x=self.batchnorm2(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        x=self.conv3(x)\n",
    "        x=self.batchnorm3(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.maxpool(x)\n",
    "        x=self.flat(x)\n",
    "        x=self.linear1(x)\n",
    "        x=self.relu(x)\n",
    "        x=self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b37df820",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nett()\n",
    "net=net.double()\n",
    "#vals[0][30][0] = vals[0][30][0].double()\n",
    "#result = (net(vals[0][30][0].double()))\n",
    "#result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4e3f57e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=1000\n",
    "lr=0.001\n",
    "batch_size=64\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "df9601f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_data=np.zeros([1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "42ac2fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_loader,lr,batch_size,loss_fn,optimizer,count):\n",
    "    size = len(train_loader)\n",
    "    for batch, (X,y) in enumerate(train_loader):\n",
    "        results = model(X.squeeze())\n",
    "        loss = loss_fn(results,y.squeeze())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch%100==0:\n",
    "            \n",
    "            print(f\"{count*5+(batch+100)/100},{loss.item()}\")\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "69ae3694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nett(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(16, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(10, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Flatten(start_dim=1, end_dim=-1)\n",
       "    (9): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "    (10): ReLU()\n",
       "    (11): Linear(in_features=1000, out_features=2, bias=True)\n",
       "  )\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(16, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(10, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (linear1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  (linear2): Linear(in_features=1000, out_features=2, bias=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (batchnorm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batchnorm3): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "beca81dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0,0.0010917062754263805\n",
      "2.0,0.0029411950877965263\n",
      "3.0,0.00227035591267906\n",
      "4.0,0.007144754943592663\n",
      "5.0,0.007296214746985474\n",
      "6.0,0.0014139966419389703\n",
      "7.0,0.0019017640713512142\n",
      "8.0,0.004408552049812862\n",
      "9.0,0.0009430263775224798\n",
      "10.0,0.05346342323372619\n",
      "11.0,0.01991451597133341\n",
      "12.0,0.0009142409909899882\n",
      "13.0,0.02941274515416649\n",
      "14.0,0.0022685191857200557\n",
      "15.0,0.00253620965202662\n",
      "16.0,0.0045669387433878\n",
      "17.0,0.03974288985339317\n",
      "18.0,0.008141173461544922\n",
      "19.0,0.0031370315352338527\n",
      "20.0,0.0047061482621655\n",
      "21.0,0.011720671381057363\n",
      "22.0,0.005744028921929743\n",
      "23.0,0.0043590013710869836\n",
      "24.0,0.003132001487793257\n",
      "25.0,0.022061614466305442\n",
      "26.0,0.021590749673581072\n",
      "27.0,0.010300921543649571\n",
      "28.0,0.003451241678479527\n",
      "29.0,0.007016734017880446\n",
      "30.0,0.010452959741050908\n",
      "31.0,0.020934380143118055\n",
      "32.0,0.022722705796183056\n",
      "33.0,0.002804767433012645\n",
      "34.0,0.021924671079575513\n",
      "35.0,0.010384770229564367\n",
      "36.0,0.0037166122217841663\n",
      "37.0,0.0017426576297444461\n",
      "38.0,0.007947044060073447\n",
      "39.0,0.00851445212996269\n",
      "40.0,0.010088016034755712\n",
      "41.0,0.03454152352357381\n",
      "42.0,0.0036729505732381435\n",
      "43.0,0.0019131483098399995\n",
      "44.0,0.05848645490893374\n",
      "45.0,0.003415903402533731\n",
      "46.0,0.03485537353735306\n",
      "47.0,0.0017741823892186233\n",
      "48.0,0.0013976718989944135\n",
      "49.0,0.02577548400570047\n",
      "50.0,0.0014194997506777028\n",
      "51.0,0.025664406432697934\n",
      "52.0,0.01040483470525616\n",
      "53.0,0.003087667231459897\n",
      "54.0,0.011024058694051361\n",
      "55.0,0.001871704016390142\n",
      "56.0,0.008309234673283808\n",
      "57.0,0.0009803907562289296\n",
      "58.0,0.05299584474024424\n",
      "59.0,0.00839825104027966\n",
      "60.0,0.007367357794661525\n",
      "61.0,0.001760572327430088\n",
      "62.0,0.01539985207302598\n",
      "63.0,0.0036745144252488095\n",
      "64.0,0.0073862389627161506\n",
      "65.0,0.06112782973679326\n",
      "66.0,0.0008291302538112693\n",
      "67.0,0.02110703213555612\n",
      "68.0,0.024315979750211537\n",
      "69.0,0.004103697033646564\n",
      "70.0,0.0008201770383891438\n",
      "71.0,0.029858197530686467\n",
      "72.0,0.01121837551399321\n",
      "73.0,0.007136601651613425\n",
      "74.0,0.0039051030935981367\n",
      "75.0,0.006347312808746194\n",
      "76.0,0.013550162799793364\n",
      "77.0,0.005723315180306844\n",
      "78.0,0.0008152748529831947\n",
      "79.0,0.03492121685475972\n",
      "80.0,0.019870359019650133\n",
      "81.0,0.028951119824408515\n",
      "82.0,0.0065536011110626635\n",
      "83.0,0.001653531163761361\n",
      "84.0,0.0029752549542221367\n",
      "85.0,0.008820263741899441\n",
      "86.0,0.0038087411261400576\n",
      "87.0,0.016521523957704606\n",
      "88.0,0.0010790057049404273\n",
      "89.0,0.02084705281685785\n",
      "90.0,0.009729809517899394\n",
      "91.0,0.005966365533829754\n",
      "92.0,0.0013869471761370352\n",
      "93.0,0.00360730985885571\n",
      "94.0,0.05864757033779655\n",
      "95.0,0.005812051495779364\n",
      "96.0,0.001223841582375631\n",
      "97.0,0.0038721350319330583\n",
      "98.0,0.010281629238696379\n",
      "99.0,0.03552078680968857\n",
      "100.0,0.007070755966929477\n",
      "101.0,0.0013047999274920963\n",
      "102.0,0.0006599370783665647\n",
      "103.0,0.003164520475439629\n",
      "104.0,0.0023863771622282494\n",
      "105.0,0.0035311038917159795\n",
      "106.0,0.01881338804237461\n",
      "107.0,0.0028213166079137297\n",
      "108.0,0.0045942354672198135\n",
      "109.0,0.011432364323317238\n",
      "110.0,0.005313482485091885\n",
      "111.0,0.000892066707874027\n",
      "112.0,0.005438801063863884\n",
      "113.0,0.002312888158496537\n",
      "114.0,0.0022080800582499555\n",
      "115.0,0.0014281914841443675\n",
      "116.0,0.00817088786367715\n",
      "117.0,0.03389696919682117\n",
      "118.0,0.001037508127521946\n",
      "119.0,0.008447047413869986\n",
      "120.0,0.004641736223148365\n",
      "121.0,0.0009640589024180286\n",
      "122.0,0.0011139191645348665\n",
      "123.0,0.005736279237959777\n",
      "124.0,0.006127278028206018\n",
      "125.0,0.0027252373759714963\n",
      "126.0,0.010970276649691895\n",
      "127.0,0.0020613342117731357\n",
      "128.0,0.007247550192410711\n",
      "129.0,0.016475499920178615\n",
      "130.0,0.004270022969846618\n",
      "131.0,0.0030108885089264433\n",
      "132.0,0.02373118712263305\n",
      "133.0,0.0010947801090077783\n",
      "134.0,0.011712342133021525\n",
      "135.0,0.026058089103620896\n",
      "136.0,0.0009940169780576573\n",
      "137.0,0.03034623657674389\n",
      "138.0,0.005768127595129695\n",
      "139.0,0.00308047242714868\n",
      "140.0,0.010975593198563947\n",
      "141.0,0.0009170938035180944\n",
      "142.0,0.001181386620303901\n",
      "143.0,0.004082703585467388\n",
      "144.0,0.003039865490270055\n",
      "145.0,0.0007895824361020929\n",
      "146.0,0.014229220317346076\n",
      "147.0,0.04819063487316835\n",
      "148.0,0.0014053196258668435\n",
      "149.0,0.003761269873814955\n",
      "150.0,0.00128097414548142\n",
      "151.0,0.0007076656065965012\n",
      "152.0,0.04440618732839464\n",
      "153.0,0.0016728481581987746\n",
      "154.0,0.0032442186118953604\n",
      "155.0,0.001987802033506931\n",
      "156.0,0.02919326995984238\n",
      "157.0,0.0022433716069245554\n",
      "158.0,0.0037856784369816473\n",
      "159.0,0.00038143009558072626\n",
      "160.0,0.019448719355974906\n",
      "161.0,0.002520052061838415\n",
      "162.0,0.002887819121145165\n",
      "163.0,0.009436637216849977\n",
      "164.0,0.004979852585989938\n",
      "165.0,0.003501871140794277\n",
      "166.0,0.007830866623609977\n",
      "167.0,0.04411304681634768\n",
      "168.0,0.0005828533986369995\n",
      "169.0,0.008263974714699146\n",
      "170.0,0.004734154824055936\n",
      "171.0,0.0164596747919807\n",
      "172.0,0.021893642948844234\n",
      "173.0,0.00540501723315751\n",
      "174.0,0.008266083722112095\n",
      "175.0,0.014464663604971747\n",
      "176.0,0.018836308193165223\n",
      "177.0,0.0009827817822650668\n",
      "178.0,0.001622909121348282\n",
      "179.0,0.001228213419745611\n",
      "180.0,0.003815446829399945\n",
      "181.0,0.0033541548726128277\n",
      "182.0,0.0030012931534849872\n",
      "183.0,0.022207885595954303\n",
      "184.0,0.01109644805492599\n",
      "185.0,0.0066316969220829814\n",
      "186.0,0.0014503451212482315\n",
      "187.0,0.0010307027929647977\n",
      "188.0,0.011960540866272884\n",
      "189.0,0.001933319228419171\n",
      "190.0,0.040895792912504114\n",
      "191.0,0.09384905762849635\n",
      "192.0,0.0019697331628780166\n",
      "193.0,0.004049399607891368\n",
      "194.0,0.003372782508363518\n",
      "195.0,0.0025335763378716955\n",
      "196.0,0.001245805895814523\n",
      "197.0,0.000844455647179784\n",
      "198.0,0.046047905663374314\n",
      "199.0,0.004983479732977771\n",
      "200.0,0.0030806720727184775\n",
      "201.0,0.009123725018328322\n",
      "202.0,0.0023544318402795293\n",
      "203.0,0.0011146888287999245\n",
      "204.0,0.0019365411126936048\n",
      "205.0,0.0028961109253913646\n",
      "206.0,0.001631531726063716\n",
      "207.0,0.003182176702745636\n",
      "208.0,0.0013956422216847735\n",
      "209.0,0.0013537567415240561\n",
      "210.0,0.007422121223278038\n",
      "211.0,0.0025422257264707303\n",
      "212.0,0.02228666226005023\n",
      "213.0,0.006917484894215373\n",
      "214.0,0.0014339724029627326\n",
      "215.0,0.0024323644236486854\n",
      "216.0,0.0008077316705369629\n",
      "217.0,0.0017849063605051268\n",
      "218.0,0.0027748033377992002\n",
      "219.0,0.004269536188010287\n",
      "220.0,0.007939891334230238\n",
      "221.0,0.0011951657739790126\n",
      "222.0,0.0006987889799077269\n",
      "223.0,0.0013812339995193342\n",
      "224.0,0.0016838012014116803\n",
      "225.0,0.005460013341726591\n",
      "226.0,0.011513014918266212\n",
      "227.0,0.0039316506409696125\n",
      "228.0,0.0011462897582868894\n",
      "229.0,0.0009566199566654006\n",
      "230.0,0.0013893019875625056\n",
      "231.0,0.0005885764767225152\n",
      "232.0,0.0024556644049867305\n",
      "233.0,0.003501895507785563\n",
      "234.0,0.04479278222630576\n",
      "235.0,0.008030159380173459\n",
      "236.0,0.011788604155362287\n",
      "237.0,0.01280639379220568\n",
      "238.0,0.018012412741915302\n",
      "239.0,0.0015950270010079348\n",
      "240.0,0.0005846517363442385\n",
      "241.0,0.002675525866637118\n",
      "242.0,0.0004181222620134305\n",
      "243.0,0.017834942011910222\n",
      "244.0,0.0013377347354278988\n",
      "245.0,0.00538717726115405\n",
      "246.0,0.0006345067863060882\n",
      "247.0,0.003356427777263456\n",
      "248.0,0.0009790817128022768\n",
      "249.0,0.019461801729337952\n",
      "250.0,0.04009806097143833\n",
      "251.0,0.009572205522986852\n",
      "252.0,0.0022235778669928885\n",
      "253.0,0.0018583019516038013\n",
      "254.0,0.004594778058595488\n",
      "255.0,0.0011639261850486342\n",
      "256.0,0.0009623191440494192\n",
      "257.0,0.0036012338315820893\n",
      "258.0,0.002360616197114961\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16896\\2113938397.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mout_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdataload\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16896\\778870282.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(model, train_loader, lr, batch_size, loss_fn, optimizer, count)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16896\\3707836539.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(0,epochs):\n",
    "    out_data[e]=train_loop(net,dataload,lr,batch_size,loss_fn,optimizer,e) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4f32555f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infected\n"
     ]
    }
   ],
   "source": [
    "if torch.argmax(net(torch.from_numpy(np.expand_dims(parasitized[12000],0)).to('cuda'))).item()==0:\n",
    "    print('infected')\n",
    "else:\n",
    "    print('Uninfected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cd4f1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'FirstWorkingModel.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
